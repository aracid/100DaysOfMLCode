# 100DaysOfMLCode
Repository of the AI journey 100 Days of ML Code
Total Time : 4 Hours

# 100 Days Of ML Code

## Day 1 : October 9th 2018
1 Hour

### Introduction into Q Learning
Difference between On Policy and Off Policies.

- Q Learning is Off Policy Method.
- Temporal differences is similar to a moving average.
- Adaptive learning rate - to assist in speed. If Alpha is too high, we may miss the sweet spot, if its too low, then its to slow to train.

### Neural Material Synthesis
Neural Material Synthesis is something that interests me, and as I am currently working on an animated feature that requires synthetic textures, this approach would make sense.

### Alpha go has been revised
  1) Only self play
  2) Predefined features, no hand crafted features.
  3) Change from inception to res-net (Residual)
  4) Combined policy and value network

### Variational Autoencoders
Compress data into a space
AutoEncoder - represent high dimensional data into low dimensional data.
VAE is different because it has 2 terms, mean and standard deviation.


**Links:**

:heavy_check_mark: [Lecture 4.5 Q-Learning Tutorial of Move 37](https://www.youtube.com/watch?v=tU6_Fc6bKyQ)

:heavy_check_mark: [Neural Material Synthesis, This Time On Steroids](https://www.youtube.com/watch?v=UkWnExEFADI&feature=em-uploademail)

:heavy_check_mark: [How AlphaGo Zero works - Google DeepMind](https://www.youtube.com/watch?v=MgowR4pq3e8)

:heavy_check_mark: [Variational Autoencoders](https://www.youtube.com/watch?v=9zKuYvjFFS8)


## Day 2 : October 10th 2018
1 Hour

### Proximal Policy Optimization

[Policy Gradient methods and Proximal Policy Optimization (PPO): diving into Deep RL!](https://www.youtube.com/watch?v=5P7I-xPq8u8)
- Learns online.
- Learns directly from the environment.
I didn't quiet follow and will have to re-watch

### Reinforcement Learning
[An introduction to Reinforcement Learning](https://www.youtube.com/watch?v=JgvyzIkgxF0)
The network that transforms input frames to output actions is called the policy network.

### Overcoming sparse rewards in Deep RL: Curiosity, hindsight & auxiliary tasks.
[Overcoming sparse rewards in Deep RL: Curiosity, hindsight & auxiliary tasks.](https://www.youtube.com/watch?v=0Ey02HT_1Ho)


## Day 3 : October 11th 2018
45 Min
[A Short Introduction to Entropy, Cross-Entropy and KL-Divergence](https://www.youtube.com/watch?v=ErfnhcEV1O8)
The best explanation of Log I've come across.
Entropy : The average amount of information you get from one sample drawn given from the probability distribution P.

[TensorFlow 2.0 Changes](https://www.youtube.com/watch?v=WTNH0tcscqo)

## Day 3 : Octover 12th 2018
4 Hours

[IBM COMMUNITY DAY : Jump Start AI at your Organization](https://www.ibmai-platform.bemyapp.com/#/conference/5bbea3d1bfd6260003e21103)
A wonderful talk by Pam Askar

https://www.ironsidegroup.com/
https://www.ironsidegroup.com/event/intro-ai-workshop/

[IBM COMMUNITY DAY : Model Asset Exchange](https://www.ibmai-platform.bemyapp.com/#/conference/5bb53d8db4ae3f00044cb9f2)

https://developer.ibm.com/code/exchanges/models/

Fabric for Deep Learning

Look at
- https://github.com/IBM/MAX-Fast-Neural-Style-Transfer
- https://github.com/IBM/MAX-Scene-Classifier
- https://kubernetes.io/
- https://developer.ibm.com/patterns/create-a-web-app-to-interact-with-machine-learning-generated-image-captions/

- [x] [Deep RL Bootcamp Lecture 4B Policy Gradients Revisited](https://www.youtube.com/watch?v=tqrcjHuNdmQ)

- [x] [PyTorch Lecture 11: Advanced CNN](https://www.youtube.com/watch?v=hqYfqNAQIjE)




# *Links*

Daily Reading Material

https://arxiv.org/list/cs.AI/recent

https://arxiv.org/list/cs.LG/recent

# Concepts to understand

- [ ] Trust Region Policy Optimization - John Schulman Berkeley
- [ ] Q-Learning
- [ ] Autoencoders
- [ ] Temporal Difference
- [ ] Reinforcement learning
- [ ] Monte Carlo Tree Search
- [ ] neural impainting
- [ ] Reinforcement Learning
- [ ] Disentangled VAE
- [ ] Transfer learning


- [ ] Image Denoiser
- [ ] Voice recognition - speech to text.
- [ ] Text to image classification, ie find an image based on text, the text isnt a category but a convnet.
- [ ] Form a sentence and form various images based on the sentence.


*Need to read*
- Disentangled VAE's (DeepMind 2016): https://arxiv.org/abs/1606.05579
- Applying disentangled VAE's to RL: DARLA (DeepMind 2017): https://arxiv.org/abs/1707.08475
- Original VAE paper (2013): https://arxiv.org/abs/1312.6114
- Reinforcement Learning with Unsupervised Auxiliary Tasks - DeepMind:https://arxiv.org/abs/1611.05397
- Curiosity Driven Exploration - UC Berkeley: https://arxiv.org/abs/1705.05363
- Hindsight Experience Replay - OpenAI: https://arxiv.org/abs/1707.01495
- [NumPy Tutorial: Data analysis with Python](https://www.dataquest.io/blog/numpy-tutorial-python/)


*Need to watch*
- [ ] [Deep RL Bootcamp](https://sites.google.com/view/deep-rl-bootcamp/lectures?authuser=0)
  - [x] [Deep RL Bootcamp Lecture 4B Policy Gradients Revisited](https://www.youtube.com/watch?v=tqrcjHuNdmQ)
- [ ] [Easier data analysis in Python with pandas](https://www.dataschool.io/easier-data-analysis-with-pandas/)

# Authors to follow

# Vloggers to follow
- [Arxiv Insights](https://www.youtube.com/channel/UCNIkB2IeJ-6AmZv7bQ1oBYg)

- [Sung Kim](https://www.youtube.com/user/hunkims/videos)
  - [x] [PyTorch Lecture 11: Advanced CNN](https://www.youtube.com/watch?v=hqYfqNAQIjE)

# Other Git Repositories

[Awesome-TensorFlow](https://github.com/jtoy/awesome-tensorflow)

[AdversarialNetsPapers](https://github.com/zhangqianhui/AdversarialNetsPapers)
